{"type":"cell","id":"048a82","pos":27,"input":"$$w = (X^T X)^{-1} X^T y$$","cell_type":"markdown"}
{"type":"cell","id":"05fd68","pos":19,"input":"plt.scatter(x, y)\nplt.title('Data')\nplt.xlabel('$x$')\nplt.ylabel('$y$')\nplt.show()","output":{"0":{"data":{"image/png":"a4c32e2596829c33a68abd276982ac513000800a"},"metadata":{"image/png":{"height":277,"width":397}},"output_type":"display_data"}},"cell_type":"code","exec_count":4}
{"type":"cell","id":"070b0a","pos":45,"input":"Plot fit residuals.","cell_type":"markdown"}
{"type":"cell","id":"073224","pos":20,"input":"### Via statistics","cell_type":"markdown"}
{"type":"cell","id":"07f5f0","pos":33,"input":"### Fitting result","cell_type":"markdown"}
{"type":"cell","id":"09669e","pos":41,"input":"Note that __MSE__ is _scale-dependent_.","cell_type":"markdown"}
{"type":"cell","id":"0a2cb8","pos":28,"input":"X = x[:, np.newaxis]\n\n# adding a column vector of \"ones\"\nXb = np.hstack((np.ones((X.shape[0], 1)), X))\nw = np.zeros(X.shape[1])\n\nz = np.linalg.inv(np.dot(Xb.T, Xb))\nw = np.dot(z, np.dot(Xb.T, y))\nb, w1 = w[0], w[1]\n\nprint('slope: {:.2f}'.format(w1))\nprint('y-intercept: {:.2f}'.format(b))","output":{"0":{"name":"stdout","output_type":"stream","text":"slope: 0.84\ny-intercept: 915.59\n"}},"cell_type":"code","exec_count":6}
{"type":"cell","id":"0d445f","pos":11,"input":"<img src=\"images/linear_regression_scheme.png\" width=\"450\" >","cell_type":"markdown"}
{"type":"cell","id":"0daf45","pos":44,"input":"rmse = np.sqrt(mse)\nprint(\"Root mean spared error\", rmse)","output":{"0":{"name":"stdout","output_type":"stream","text":"Root mean spared error 0.468189371853\n"}},"cell_type":"code","exec_count":10}
{"type":"cell","id":"0f7055","pos":39,"input":"$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} \\big(y_i - \\hat{y}_i\\big)^2$$","cell_type":"markdown"}
{"type":"cell","id":"108ddb","pos":46,"input":"plt.scatter(np.arange(x.shape[0]), y - y_predicted)\nplt.ylabel('$y - \\hat{y}$')\nplt.xlabel('$x$')\nplt.title('Fit residue')\nplt.axhline(0., color='k')","output":{"0":{"data":{"text/plain":"<matplotlib.lines.Line2D at 0x7f19e61d4e10>"},"output_type":"execute_result","exec_count":11},"1":{"data":{"image/png":"343e3e95396879e0a5d0f24c98d333ea8637f258"},"metadata":{"image/png":{"height":277,"width":399}},"output_type":"display_data"}},"cell_type":"code","exec_count":11}
{"type":"cell","id":"17ae5c","pos":47,"input":"### Coefficient of determination ($R^2$)","cell_type":"markdown"}
{"type":"cell","id":"1babeb","pos":0,"input":"# Assignment \\# 1 - Jupyter Notebook","cell_type":"markdown"}
{"type":"cell","id":"238432","pos":13,"input":"(text: 2 pts; code: 3 pts)","cell_type":"markdown"}
{"type":"cell","id":"279d7f","pos":14,"input":"Import some modules.","cell_type":"markdown"}
{"type":"cell","id":"2a3e63","pos":16,"input":"The cell below produce a __synthetic dataset__ with randomly generated noise.","cell_type":"markdown"}
{"type":"cell","id":"2d1f5b","pos":30,"input":"(text: 3 pts; code: 1 pt)","cell_type":"markdown"}
{"type":"cell","id":"30b624","pos":21,"input":"(text: 1 pt; equation: 10 pts; code 1 pt)","cell_type":"markdown"}
{"type":"cell","id":"384685","pos":23,"input":"cov_xy = np.cov(np.vstack((x, y)), ddof=0)[0, 1]\nvar_x = np.var(x, ddof=0)\nw1 = cov_xy / var_x\nb = np.mean(y) - w1*np.mean(x)\n\nprint('slope: {:.2f}'.format(w1))\nprint('y-intercept: {:.2f}'.format(b))","output":{"0":{"name":"stdout","output_type":"stream","text":"slope: 0.84\ny-intercept: 915.59\n"}},"cell_type":"code","exec_count":5}
{"type":"cell","id":"3c15db","pos":43,"input":"Root mean squared error:","cell_type":"markdown"}
{"type":"cell","id":"45cb32","pos":38,"input":"Mean squared error (MSE):","cell_type":"markdown"}
{"type":"cell","id":"466b55","pos":22,"input":"Using statistics:\n\n$$w_1 = \\frac{\\sigma_{xy}}{\\sigma_{x}^{2}}$$\n\n$$b = \\bar{y} - w_1\\bar{x}$$\n\nwhere $\\sigma_{xy}$ is the covariance, $\\sigma_{xy} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$, and $\\sigma^{2}_{x}$ is the variance, $\\sigma^{2}_{x} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$.  $\\bar{x}$ and $\\bar{y}$ are averages of $x$ and $y$, respectively. ","cell_type":"markdown"}
{"type":"cell","id":"473615","pos":5,"input":"The example here shows how to conduct least-squares linear regression with python.  This is quite common task in scientific data analysis.  The notebook you make here can be also a good template to keep for future use for least-squares fitting. ","cell_type":"markdown"}
{"type":"cell","id":"4a1453","pos":31,"input":"You may use the __polyfit__ function in __numpy__.","cell_type":"markdown"}
{"type":"cell","id":"584104","pos":36,"input":"### Evaluation of fitting","cell_type":"markdown"}
{"type":"cell","id":"66ad0c","pos":29,"input":"### Using a pre-implemented function","cell_type":"markdown"}
{"type":"cell","id":"6a3dac","pos":7,"input":"(text: 4 pts; figure: 5 pts)","cell_type":"markdown"}
{"type":"cell","id":"7867aa","pos":9,"input":"__(Note)__ The figure file can be found under the folder for this file (see blow).","cell_type":"markdown"}
{"type":"cell","id":"7bd0b9","pos":48,"input":"(text: 4 pts; equation: 4 pts; code: 1 pt)","cell_type":"markdown"}
{"type":"cell","id":"87b58f","pos":6,"input":"### Background","cell_type":"markdown"}
{"type":"cell","id":"8aa26f","pos":1,"input":"__(Instruction)__ The purpose of this assignment is to make sure you know how to use Jupyter Notebook as a scientific coding environment for python.  Jupyter notebook provides a range of different functions for scientific documentation combined with codes.  In this assignment, a fully functioning jupyter notebook is provided as a hard copy and you will produce exactly the same jupyter notebook by filling in the cells below in this notebook. \n\n- The format of text should be exactly the same as the hard copy, including bold face, italics, headers, etc (19 pt, 1 pt for each markdown cell with formatted texts).\n\n- The format of equations should be exactly the same as the hard copy, including italics, non-italics, subscripts, superscripts, etc (19 pt; 1 pt for each equation).\n\n- The figure should be imported properly (5 pt).\n\n- The codes should work without any error (11 pt; 1 pt for each code cell).\n\n__(Due)__ 2018/1/30 9:00pm\n\n__(Where to find the hardcopy)__ It is under the same folder as this notebook.  The name is \"assignment_1-hardcopy.pdf\"","cell_type":"markdown"}
{"type":"cell","id":"8b045e","pos":40,"input":"where $\\hat{y}$ is predicted average $y$ value for a given $x$.","cell_type":"markdown"}
{"type":"cell","id":"8b5f3a","pos":15,"input":"import numpy as np\nimport scipy.stats\nimport matplotlib.pyplot as plt\n%matplotlib inline","cell_type":"code","exec_count":2}
{"type":"cell","id":"9439fd","pos":34,"input":"(text: 1 pt; code: 1 pt)","cell_type":"markdown"}
{"type":"cell","id":"9dbcab","pos":42,"input":"y_predicted = x*w1 + b\nmse = np.mean((y - y_predicted)**2)\nprint(\"Mean squared error = \", mse)","output":{"0":{"name":"stdout","output_type":"stream","text":"Mean squared error =  0.219201287916\n"}},"cell_type":"code","exec_count":9}
{"type":"cell","id":"a422d0","pos":25,"input":"(text: 1 pt; equation: 1 pt; code: 1 pt)","cell_type":"markdown"}
{"type":"cell","id":"ac35a7","pos":2,"input":"***","cell_type":"markdown"}
{"type":"cell","id":"afa219","pos":37,"input":"(text: 3 pts; equation: 4 pts; code: 3 pts)","cell_type":"markdown"}
{"type":"cell","id":"b00c20","pos":17,"input":"rng = np.random.RandomState(123)\nmean = [100, 1000]\ncov = [[1, 0.9], [0.9, 1]]\nsample = rng.multivariate_normal(mean, cov, size=100)\nx, y = sample[:, 0], sample[:, 1]","cell_type":"code","exec_count":3}
{"type":"cell","id":"b11359","pos":32,"input":"w = np.polyfit(x, y, deg=1)\nb, w1 = w[1], w[0]\nprint('slope: {:.2f}'.format(w1))\nprint('y-intercept: {:.2f}'.format(b))","output":{"0":{"name":"stdout","output_type":"stream","text":"slope: 0.84\ny-intercept: 915.59\n"}},"cell_type":"code","exec_count":7}
{"type":"cell","id":"b3e9c2","pos":4,"input":"(text: 1 pt)","cell_type":"markdown"}
{"type":"cell","id":"c597a3","pos":24,"input":"### Via linear algebra","cell_type":"markdown"}
{"type":"cell","id":"c85118","pos":12,"input":"### Synthesize a dataset","cell_type":"markdown"}
{"type":"cell","id":"cc1f38","pos":49,"input":"- Total sum of squares (variability of the reponse or target variable, proportional to variance):\n\n$$SS_{total} = \\sum_{i=1}^{n} \\big( y_i - \\bar{y_i} \\big)^2$$\n\n- Residual sum of squares:\n\n$$SS_{residual} = \\sum_{i=1}^{n} \\big( \\hat{y}_i - \\bar{y}_i \\big)^2$$\n\n- Coefficient of determination\n\n$$R^2 = \\frac{SS_{residual}}{SS_{total}}$$","cell_type":"markdown"}
{"type":"cell","id":"d50331","pos":35,"input":"extremes = np.array([np.min(x), np.max(x)])\npredict = extremes * w1 + b\n\nplt.plot(x, y, marker='o', linestyle='')\nplt.plot(extremes, predict)\nplt.title(\"Fitting result\")\nplt.xlabel('$x$')\nplt.ylabel('$y$')\nplt.show()","output":{"0":{"data":{"image/png":"03dabfe8a0b88e91ec8f5bb56cb9978e019271de"},"metadata":{"image/png":{"height":277,"width":397}},"output_type":"display_data"}},"cell_type":"code","exec_count":8}
{"type":"cell","id":"de6712","pos":3,"input":"## Least-Squares Linear Regression","cell_type":"markdown"}
{"type":"cell","id":"df6ea1","pos":26,"input":"Analytical solution:","cell_type":"markdown"}
{"type":"cell","id":"e3d78f","pos":18,"input":"Plot the synthetic dataset.","cell_type":"markdown"}
{"type":"cell","id":"e9fc87","pos":8,"input":"In this notebook, we will find a pair of __slope__ and __intercept__ that _minimizes_ the sum of the residuals (vertical offsets or distances) for a synthetic dataset.  The figure below also shows the main idea of least-squares linear regression.  ","cell_type":"markdown"}
{"type":"cell","id":"ef1de3","pos":50,"input":"mean_y = np.mean(y)\nSS_total = np.sum((y - mean_y)**2)\nSS_residual = np.sum((y_predicted - mean_y)**2)\nr_squared = SS_residual / SS_total\nprint(\"Coefficient of determination = \", r_squared)","output":{"0":{"name":"stdout","output_type":"stream","text":"Coefficient of determination =  0.766539284928\n"}},"cell_type":"code","exec_count":12}
{"type":"cell","id":"f390fb","pos":10,"input":"%ls ./images","output":{"0":{"name":"stdout","output_type":"stream","text":"/bin/sh: /ext/anaconda3/lib/libtinfo.so.5: no version information available (required by /bin/sh)\r\nlinear_regression_scheme.png\r\n"}},"cell_type":"code","exec_count":1}
{"type":"file","last_load":1516729076892}
{"type":"settings","kernel":"anaconda3","kernel_state":"idle","backend_state":"running","trust":true,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"}},"kernel_usage":{"cpu":0,"memory":106094592}}